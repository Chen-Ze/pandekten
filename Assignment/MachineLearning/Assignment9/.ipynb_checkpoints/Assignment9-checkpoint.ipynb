{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELE 435/535 Homework 3: Gradient Descent and Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Neural Networks\n",
    "\n",
    "In this part, we will use Keras and TensorFlow to train a neural network on MNIST dataset. We will compare the neural network with a multinomial softmax regression. Write the code for training these two models.\n",
    "\n",
    "There are two options to do this: (1) Install TensorFlow as descibed below,   \n",
    "OR   \n",
    "use Google's Colab. Option 2 offers the potential of faster machines and a nice jupyter notebook style API. The code and results you write and run on Colab can be downloaded as a Jupyter notebook. NOTE: the load on Colab varies over time so don't wait to the last day to use Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TensorFlow Installation\n",
    "\n",
    "TensorFlow is a free and an open source software library for numerical computation using data flow graphs. It was originally developed by researchers and engineers working on the Google Brain Team within Google's Machine Intelligence research organization for the purposes of conducting machine learning and deep neural networks research. However, it's applicable in a wide variety of other domains as well.\n",
    "\n",
    "1. Install Anaconda by following the instructions here https://www.anaconda.com/download. This should work for all MAC, Linux and Windows operating systems.\n",
    "2. Open your Anaconda terminal and create a new environment called tensorflow using the following command: <br> conda create -n tensorflow python=3.6 <br>\n",
    "3. Now, activate your tensorflow environment by typing <br> source activate tensorflow (MAC and Linux) <br> activate tensorflow (Windows) <br>\n",
    "4. Once the new envoironment is activated, we are going to install the following packages:<br> conda install ipython <br> conda install jupyter <br> conda install matplotlib <br> conda install -c conda-forge tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import keras from Tensorflow\n",
    "There are many well-written tutorials on how to use TensorFlow. For example, see:  <br> https://www.datacamp.com/community/tutorials/tensorflow-tutorial <br>\n",
    "Further, these days high-level APIs such as Keras has made it very easy to train very deep neural networks. For example, simply with 4-5 lines of code with Keras running on top of TensorFlow (https://www.tensorflow.org/tutorials/), you can get more than 95% test accuracy on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 03:14:55.713759: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# This code is provided\n",
    "import tensorflow as tf\n",
    "#print('tensorflow:', tf.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "#print('keras: ', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the MINST dataset from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "Training images shape: (30000, 28, 28)\n",
      "Training labels shape: (30000,)\n",
      "Testing images shape: (10000, 28, 28)\n",
      "Training labels shape: (10000,)\n",
      "Reshaped training images shape: (30000, 784)\n",
      "Training labels shape: (30000,)\n",
      "One-hot encoded training labels shape: (30000, 10)\n",
      "One-hot encoded testing labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# This code is provided\n",
    "# download the data\n",
    "num_train = 30000\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images_2d, train_labels), (test_images_2d, test_labels) = mnist.load_data()\n",
    "train_images_2d = train_images_2d[0:num_train,:,:]\n",
    "train_labels = train_labels[0:num_train]\n",
    "print('Training images shape:',train_images_2d.shape)\n",
    "print('Training labels shape:',train_labels.shape)\n",
    "print('Testing images shape:',test_images_2d.shape)\n",
    "print('Training labels shape:',test_labels.shape)\n",
    "\n",
    "# reshape and scale the images\n",
    "train_images = train_images_2d.reshape(num_train,28*28)\n",
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images_2d.reshape(10000, 28*28)\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "print('Reshaped training images shape:', train_images.shape)\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "\n",
    "# process the labels to one-hot encoded form\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print('One-hot encoded training labels shape:', train_labels.shape)\n",
    "print('One-hot encoded testing labels shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training a multinomial softmax regression using Keras/TensorFlow on MNIST\n",
    "Write the code for training multinomial softmax regression using the keras API. The network is 784 (the size of the input layer) -> 10 (the size of the output layer) -> softmax (activiation function for the output layer). Then After training for 5 epochs, report the testing loss and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MSReg_4_MNIST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 03:15:10.739514: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#This code is given to you \n",
    "\n",
    "MSReg = keras.models.Sequential(name='MSReg_4_MNIST')\n",
    "\n",
    "MSReg.add(keras.layers.Dense(10, activation='softmax', input_shape=(28*28,)))\n",
    "\n",
    "MSReg.compile(optimizer = 'RMSprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "MSReg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 1s 917us/step - loss: 0.8058 - accuracy: 0.8095\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 0s 800us/step - loss: 0.3888 - accuracy: 0.8963\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.3346 - accuracy: 0.9082\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.3115 - accuracy: 0.9146\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 0s 765us/step - loss: 0.2970 - accuracy: 0.9178\n",
      "test_loss 0.292217880487442\n",
      "test_acc 0.9168999791145325\n"
     ]
    }
   ],
   "source": [
    "# This code is given to you\n",
    "MSReg.fit(train_images, train_labels, epochs=5, batch_size=128, verbose=1)\n",
    "\n",
    "test_loss, test_acc = MSReg.evaluate(test_images, test_labels, verbose=0)\n",
    "print('test_loss', test_loss)\n",
    "print('test_acc', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training an multilayer perceptron (MLP) using Keras/TensorFlow on MNIST\n",
    "Write the code for training an MLP using keras API. The model parameter is 784 (the size of the input layer) -> 512 (middle hidden layer) -> relu (activiation function for the middle hidden layer) -> 10 (the size of the output layer) -> softmax (activiation function for the output layer). Then report the testing loss and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Uno_HL_NN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#This code is given to you\n",
    "Uno_HL = keras.models.Sequential(name='Uno_HL_NN')\n",
    "Uno_HL.add(keras.layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "Uno_HL.add(keras.layers.Dense(10, activation='softmax'))\n",
    "Uno_HL.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "Uno_HL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3449 - accuracy: 0.9025\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1486 - accuracy: 0.9569\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9703\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0687 - accuracy: 0.9789\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0513 - accuracy: 0.9847\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0369 - accuracy: 0.9896\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9927\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9948\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9963\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9972\n",
      "test_loss 0.089570052921772\n",
      "test_acc 0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "#This code is given to you\n",
    "Uno_HL.fit(train_images, train_labels, epochs=10, batch_size=128, verbose=1)\n",
    "\n",
    "test_loss, test_acc = Uno_HL.evaluate(test_images, test_labels, verbose=0)\n",
    "print('test_loss', test_loss)\n",
    "print('test_acc', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training a convolutional neural network (CNN) using Keras/TensorFlow on MNIST\n",
    "Write the code for training a CNN using keras API. The first layer is the size of 64 with the kernel size of 3 and the relu activation; the second layer is the size of 32 with the kernel size of 3 and the relu activation, followed by faltten layer and the final output layer is 10 (the size of the output layer). Then report the testing loss and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_2d_reshape = train_images_2d[:,:,:,None]\n",
    "test_images_2d_reshape = test_images_2d[:,:,:,None]\n",
    "\n",
    "# Train\n",
    "\n",
    "\n",
    "# Test and print results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison between these three models\n",
    "Which model is better? Please comment on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Autoencoder\n",
    "In this part, we will use Keras and TensorFlow to train an autoencoder on MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training an autoencoer (MLP) using Keras/TensorFlow on MNIST\n",
    "Write the code for training an MLP using keras API. The model parameter is 784 (the size of the input layer) -> 512 (middle hidden layer) -> relu (activiation function for the middle hidden layer) -> 10 (the size of the middle representation) -> 512 (middle hidden layer) -> relu (activiation function for the middle hidden layer) -> 784 (the size of the input). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               5632      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 814,874\n",
      "Trainable params: 814,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This code is given to you\n",
    "AE = keras.models.Sequential(name='AE')\n",
    "AE.add(keras.layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "AE.add(keras.layers.Dense(10, activation='relu'))\n",
    "AE.add(keras.layers.Dense(512, activation='relu'))\n",
    "AE.add(keras.layers.Dense(784, activation='relu'))\n",
    "AE.compile(optimizer = 'rmsprop',\n",
    "               loss = 'MSE')\n",
    "\n",
    "AE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model, then report the testing loss and testing accuracy.\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot the reconstructed images\n",
    "Write the code for randomly plotting 10 image paris of the orginal and reconstrated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vary the size of the middle representations.\n",
    "Write the code for randomly plotting 10 image paris of the orginal and reconstrated images with the size of the middle representation being 5, 2, and 1.\n",
    "\n",
    "Suggestion: write the model specification and the training as a function with the size of the middle layer as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use Matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "AE = model_AE(5)\n",
    "decoded_imgs = AE.predict(test_images)\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What do you observe for varying the size of representations?\n",
    "Please comment on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
